---
title: "Thesis Project"
author: "Chandramouli Guna"
date: "05/09/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars, warning=FALSE}
library(igraph)
library(ggraph)
library(poweRlaw)
library(factoextra)
library(cluster)
library(clValid)
data <- read.csv('soc-redditHyperlinks-body.tsv',sep = "\t")
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
data_fr <-data.frame(data)
g <- graph_from_data_frame(data_fr)
# g <-make_graph(edges = c(data$SOURCE_SUBREDDIT,data$TARGET_SUBREDDIT), directed = TRUE)
```



##getting features of ego networks
```{r}

ego.data <-lapply(unique(V(g)$name) , function(x){
  # print(i)
 vertex <- toString(x)
 # print(x)
 x<-subgraph.edges(g,incident(g, V(g)[x]))
  if(length(V(x))>20){
  # print(vertex)
  bi.number <-0
  for (v in V(x)) {
    if((are_adjacent(x,V(x)[vertex],v)==TRUE) && (are_adjacent(x,v,V(x)[vertex])) && (v != V(x)[vertex])){
      bi.number = bi.number + 1
    }
  }
  bi_ratio <- bi.number/length(V(x))
  dd_degree<-degree(x, mode="out")
  # print(dd_degree)
  mean_deg<- mean(dd_degree)
  sd_deg<-sd(dd_degree)
  # As we are analysing out-degree only here, several nodes may have no outward connections (they may only receive phonecalls) and will have degree zero.    I remove these few nodes with out-degree of zero.

  
  dd_degree<-degree(x, mode="in")
  probs = dpois(1:length(dd_degree),lambda=mean(dd_degree))
  comp = 1-sum(probs)
  ch <-chisq.test(c(dd_degree,0), p=c(probs, comp),simulate.p.value = TRUE)[[3]]
  if(is.na(ch)){
    ch<-0
  }
  else {
    if(ch >0.05){
      ch<-1
    }
    else {
      ch <-0
    }
  }
  pw <-power.law.fit(dd_degree, impelementation = "plfit",simulate.p.value = TRUE)$KS.p
  if(is.na(pw)){
    pw<-0
  }
  else {
    if(pw >0.05){
      pw<-1
    }
    else {
      pw <-0
    }
  }
  
  # calculating initialization score for each community

  posit_sent <- lapply(E(x)$PROPERTIES, function(x){
    prop <- as.list(strsplit(x, ",")[[1]])[[19]]
    as.double(prop)
  })
  posit_sent_score <- mean(unlist(posit_sent))
  
  neg_sent <- lapply(E(x)$PROPERTIES, function(x){
    prop <- as.list(strsplit(x, ",")[[1]])[[20]]
    as.double(prop)
  })
  neg_sent_score <- mean(unlist(neg_sent))
  neut_sent <- lapply(E(x)$PROPERTIES, function(x){
    prop <- as.list(strsplit(x, ",")[[1]])[[21]]
    as.double(prop)
  })
  pos <-0
  neg <-0
  prop <-strsplit(E(x)$PROPERTIES,",")
  for (i in c(1,length(prop))) {
    if(E(x)$LINK_SENTIMENT[i]>0){pos <<- pos + 1}
    else{neg <<- neg-1}
    
    
    
  }
  
  neut_sent_score <- mean(unlist(neut_sent))
  # pos <-0
  # neg <-0
  del <- lapply(E(x)$LINK_SENTIMENT, function(x){
    if(x>=0){pos <<- pos + 1}
    else{neg <<- neg-1}
    
  })
  
  pos <- pos / length(E(x))
  
  neg <- abs(neg) / length(E(x))
  
  #calculating initialization score
  ini <- lapply(V(x)$name, function(y){
    e <-E(x)[vertex  %--% y]
    # print(e)
    # print(toString(tail_of(x, e[e$TIMESTAMP == min(e$TIMESTAMP)])$name))
    if(toString(tail_of(x, e[e$TIMESTAMP == min(e$TIMESTAMP)])$name)==vertex){ score <-  1}
    else {score <- 0}
  })
  ini_score <-mean(unlist(ini))
  # print(ini)
  
  return(c(vertex, as.double(length(V(x))),as.double(length(E(x))),as.double(bi_ratio),ch,pw,as.double(pos),as.double(neg),
           ini_score))
}
else{
  # i=i+1
  return(NULL)
}
})



##filtering out null vallues 
ego.data1 = Filter(Negate(is.null), ego.data)
feature.df1 <-data.frame(matrix(unlist(ego.data1),ncol = 9,byrow = TRUE))
feature.df <- feature.df1[,-1]
rownames(feature.df)<-feature.df1[,1]

feature.df <-transform(feature.df,
                      X2 = as.double(X2),
                      X3 = as.double(X3),
                      X4 = as.double(X4),
                      X5 = as.double(X5),
                      X6 = as.double(X6),
                      X7 = as.double(X7),
                      X8 = as.double(X8),
                      X9 = as.double(X9))
colnames(feature.df) <-c("No_nodes","No_edges","Bi_ratio","Poisson_low","Power Law",
                                                 "Pos sent score", "neg sent score",
                                                 "initialization score")

```




##clustering obtained ego networks with features
```{r}
install.packages("factoextra")
library(factoextra)
library(cluster)
feature.df.scaled <- data.frame(scale(feature.df))

distance <- get_dist(feature.df.scaled)

feature.df.scaled2 <- feature.df.scaled[,c("No_nodes","No_edges","Bi_ratio",
                                                 "Pos.sent.score", "neg.sent.score",
                                                 "initialization.score")]
fviz_dist(distance, gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
fviz_nbclust(feature.df.scaled2, kmeans, method = "wss",k.max=20) #wss silhouette
 km.res <- kmeans(feature.df.scaled2,10, nstart = 25)

str(km.res)
km.res$cluster[km.res$cluster==2]

```




```{r}

c1<-feature.df[names(km.res$cluster[which(km.res$cluster==1)]),]
c2 <-feature.df[names(km.res$cluster[which(km.res$cluster==2)]),]
c3 <-feature.df[names(km.res$cluster[which(km.res$cluster==3)]),]
c4 <-feature.df[names(km.res$cluster[which(km.res$cluster==4)]),]
c5 <-feature.df[names(km.res$cluster[which(km.res$cluster==5)]),]
c6 <-feature.df[names(km.res$cluster[which(km.res$cluster==6)]),]
summary(c1)
summary(c2)
summary(c3)
summary(c4)
summary(c5)
summary(c6)
feature.df[names(km.res$cluster[which(km.res$cluster==1)]),]
```





```{r}
library(kableExtra)
intern <- clValid(feature.df.scaled2, nClust = 2:30, 
              clMethods = c("hierarchical","kmeans"), validation = "internal", metric="correlation",maxitems=30000,iter.max=30,method=c("ward", "single", "complete","average"))
summary(intern) %>% kable() %>% kable_styling()

```

here we are trying with 24 cluisters as well
```{r}
library(dplyr)
distance <- get_dist(feature.df[c("No_nodes","No_edges","Bi_ratio",
                                                 "Pos sent score", "neg sent score",
                                                 "initialization score")])

distance <- get_dist(feature.df.scaled2)
clusters <- hclust(distance, )

plot(clusters)
rect.hclust(clusters , k = 6, border = 2:6)
clusterCut <- cutree(clusters, 24)
table(clusterCut)
feature.df_hclust <- feature.df
feature.df_hclust["noe_edge_ratio"] <- feature.df_hclust$No_edges / feature.df_hclust$No_nodes
feature.df_hclust["Clustnumber"] <-clusterCut
c <-list()
table(clusterCut)
for (i in c(1:length(table(clusterCut)))) {
  print(i)
  # c <-append(c,feature.df_hclust[feature.df_hclust$Clustnumber==i,])
  print(summary(feature.df_hclust[feature.df_hclust$Clustnumber==i,]))
}


classification_data <- feature.df_hclust %>% select(c("No_nodes","No_edges","Bi_ratio","Pos sent score", "neg sent score","initialization score","Clustnumber")) %>%
  mutate(class = case_when(Clustnumber == 1 | Clustnumber == 7 | Clustnumber ==18 | Clustnumber == 21~ "unpopular joining conversationalists",
                           Clustnumber == 4 ~ "joining conversationalists",
                           Clustnumber == 2 | Clustnumber ==6 ~ "Initiators",
                           Clustnumber == 3 ~ "Possitive participants",
                           Clustnumber == 5 | Clustnumber == 14 | Clustnumber == 20 | Clustnumber == 24 ~ "Taciturn",
                           Clustnumber == 8 | Clustnumber ==10 | Clustnumber == 11 | Clustnumber ==16 | Clustnumber ==23  ~ "Ignored",
                           Clustnumber == 12 ~"Elitists",
                           Clustnumber == 17 ~ "popular participants",
                           Clustnumber == 22 ~ "Negative Initiators",
                           Clustnumber == 9 | Clustnumber == 13 | Clustnumber == 15 | Clustnumber == 19 ~ "extremely large network (outliers)"
                           ))  %>% select(c("No_nodes","No_edges","Bi_ratio","Pos sent score", "neg sent score","initialization score","class"))


classification_data$class <- as.factor(classification_data$class)
```








```{r}
library(e1071)
library(MLmetrics)
library(ROCR)
library(pROC)
library(mltools)
library(caret)
library(rpart)
n <- nrow(classification_data)
ntrain <- round(n*0.75)
tindex <- sample(n, ntrain)
train_data <- classification_data[tindex,]
test_data <- classification_data[-tindex,]

y = train_data$class
x= train_data[,-7]
svm1 <- svm(x,y, 
          type="C-classification", kernal="radial", 
          gamma=0.1, cost=10)

summary(svm1)
svm1$SV

pred <- predict(svm1, test_data[,-7])
xtab <- as.matrix(table(test_data$class, pred))
xtab

rowsums = apply(xtab, 1, sum) # number of instances per class
colsums = apply(xtab, 2, sum) # number of predictions per class




diag_data <- diag(xtab)
accuracy <-  sum(diag_data)/sum(xtab)
precision = diag_data / colsums
recall = diag_data / rowsums 
f1 = 2 * precision * recall / (precision + recall) 
 
metrics <-data.frame(precision, recall, f1) 
summary(metrics)
```
